{"cells":[{"cell_type":"markdown","metadata":{"id":"xJ_5vemHnXlZ"},"source":["구글 드라이브 연동"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-1-veNcnW6U","outputId":"1aeb2940-0bdd-448c-ed96-0baf7b8d0064"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"G1NrfEiTnlLS"},"source":["폴더 경로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oW1RJXWnkxw"},"outputs":[],"source":["workspace_path = '/gdrive/My Drive/Colab Notebooks/CV2022/competition'  # 파일 업로드한 경로 반영"]},{"cell_type":"markdown","metadata":{"id":"86ea40c7"},"source":["### 필요한 패키지 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRfwuEL2--n-","outputId":"f58dedc2-f681-43bc-9d8d-3e01a7d9195e"},"outputs":[],"source":["!pip install albumentations==0.4.6\n","!pip install yacs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52bbfdfb"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn.functional as F\n","import yaml\n","import numpy as np\n","import cv2\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import random\n","import torch.backends.cudnn as cudnn\n","import time\n","from torchvision import models\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"649609b1"},"source":["### 재구현 세팅"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c35eec19"},"outputs":[],"source":["def init_seeds(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n","    if seed == 0:  # slower, more reproducible\n","        cudnn.deterministic = True\n","        cudnn.benchmark = False\n","    else:  # faster, less reproducible\n","        cudnn.deterministic = False\n","        cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b90c4ec5"},"outputs":[],"source":["init_seeds(1)"]},{"cell_type":"markdown","metadata":{"id":"3f8a343a"},"source":["### 데이터 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"499b3f23"},"outputs":[],"source":["rgb_path = os.path.join(workspace_path, 'data/train/rgb/')\n","ngr_path = os.path.join(workspace_path, 'data/train/ngr/')\n","label_path = os.path.join(workspace_path, 'data/train/label/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4e26b49"},"outputs":[],"source":["rgb_images = os.listdir(rgb_path)\n","rgb_images = [os.path.join(rgb_path,x) for x in rgb_images]\n","ngr_images = os.listdir(ngr_path)\n","ngr_images = [os.path.join(ngr_path, x) for x in ngr_images]\n","label_images = os.listdir(label_path)\n","label_images = [os.path.join(label_path, x) for x in label_images]"]},{"cell_type":"markdown","metadata":{"id":"997d5237"},"source":["### 데이터셋 클래스 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ca96420c"},"outputs":[],"source":["class CloudDataset(torch.utils.data.Dataset):\n","    def __init__(self, image_path, label_path, patch_size = 400, patch_stride = 100, is_train = True, cache_dir = './cache', transforms = None):\n","        self.image_path = image_path\n","        self.label_path = label_path\n","        self.patch_size = patch_size\n","        self.patch_stride = patch_stride\n","        self.is_train = is_train\n","        self.transforms = transforms\n","        \n","        self.patch_images = []\n","        self.patch_labels = []\n","        \n","        \n","        cache_dir = cache_dir\n","        os.makedirs(cache_dir, exist_ok=True)\n","        if is_train:\n","            for img_path in self.image_path:\n","                img = cv2.imread(img_path)\n","                img_count = 0\n","                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n","                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n","                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n","                        patch_path = f'rgb_{os.path.splitext(os.path.basename(img_path))[0]}_{img_count}.png'\n","                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n","                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n","                        self.patch_images.append(os.path.join(cache_dir, patch_path))\n","                        img_count += 1\n","\n","            for label_path in self.label_path:\n","                img = cv2.imread(label_path)\n","                img_count = 0\n","                for x in range(0, img.shape[0]-self.patch_size+1, self.patch_stride):\n","                    for y in range(0, img.shape[1]-self.patch_size+1, self.patch_stride):\n","                        patch_image = img[x:x+patch_size, y:y+patch_size, :].copy()\n","                        patch_path = f'label_{os.path.splitext(os.path.basename(label_path))[0]}_{img_count}.png'\n","                        if not os.path.isfile(os.path.join(cache_dir, patch_path)):\n","                            cv2.imwrite(os.path.join(cache_dir, patch_path), patch_image)\n","                        self.patch_labels.append(os.path.join(cache_dir, patch_path))\n","                        img_count += 1\n","        else:\n","            self.patch_images = self.image_path\n","            self.patch_labels = self.label_path\n","    def __len__(self):\n","        return len(self.patch_images)\n","        \n","    def __getitem__(self, idx):\n","        img = cv2.imread(self.patch_images[idx])\n","        \n","        if self.is_train:\n","            label = cv2.imread(self.patch_labels[idx])\n","            # numpy arrays to tensors\n","            h, w = label.shape[:2]\n","        \n","            target = np.zeros((h, w), dtype=np.uint8)\n","            pos = np.where(np.all(label == [0, 0, 255], axis=-1))  # thick cloud\n","            target[pos] = 1\n","            pos = np.where(np.all(label == [0, 255, 0], axis=-1))  # thin cloud\n","            target[pos] = 2\n","            pos = np.where(np.all(label == [0, 255, 255], axis=-1))  # cloud shadow\n","            target[pos] = 3\n","        else:\n","            target = img\n","        if self.transforms is not None:\n","            img, target = self.transforms(img, target)\n","            \n","        if self.is_train:\n","            return img, target\n","        else:\n","            return img, self.patch_images[idx]"]},{"cell_type":"markdown","metadata":{"id":"09d79e8b"},"source":["### 파라미터 세팅"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6ac4eae"},"outputs":[],"source":["batch_size = 8\n","epochs = 10\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","patch_size = 400\n","patch_stride = 100\n","num_workers = 0\n","\n","num_classes = 4\n","class_names = ['thick cloud', 'thin cloud', 'cloud shadow']\n","\n","train_data_rate = 0.7\n","\n","model_name = 'dilated_unet'\n","\n","loss_func = 'dice'"]},{"cell_type":"markdown","metadata":{"id":"7e4513b1"},"source":["### 데이터증대"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17dc2c12"},"outputs":[],"source":["class ImageAug:\n","    def __init__(self):\n","        self.aug = A.Compose([A.HorizontalFlip(p=0.5),\n","                             A.VerticalFlip(p=0.5),\n","                             A.ShiftScaleRotate(p=0.5),\n","                             A.RandomBrightnessContrast(p=0.3),\n","                             A.Normalize(),\n","                             ToTensorV2()])\n","\n","    def __call__(self, img, label):\n","        transformed = self.aug(image=img, mask=label)\n","        return transformed['image'], transformed['mask']\n","\n","class DefaultAug:\n","    def __init__(self):\n","        self.aug = A.Compose([A.Normalize(),\n","                             ToTensorV2()])\n","\n","    def __call__(self, img, label):\n","        transformed = self.aug(image=img, mask=label)\n","        return transformed['image'], transformed['mask']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03a59423"},"outputs":[],"source":["train_transforms = ImageAug()\n","val_transforms = DefaultAug()"]},{"cell_type":"markdown","metadata":{"id":"2147f462"},"source":["### 데이터셋 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98bed485"},"outputs":[],"source":["#train dataset\n","train_dataset = CloudDataset(rgb_images[:int(len(rgb_images)*train_data_rate)], label_images[:int(len(label_images)*train_data_rate)],\n","                            transforms=train_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n","                                               num_workers=num_workers, pin_memory=True, drop_last=True)\n","\n","#valid dataset\n","val_dataset = CloudDataset(rgb_images[int(len(rgb_images)*train_data_rate):], label_images[int(len(label_images)*train_data_rate):],\n","                            transforms=val_transforms, cache_dir=os.path.join(workspace_path, 'cache'))\n","val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True,\n","                                               num_workers=num_workers, pin_memory=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"55cbab53"},"source":["### 모델 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e54a2c7d"},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIK90NknzGPn"},"outputs":[],"source":["import torch.nn as nn\n","\n","class DoubleConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConvBlock, self).__init__()\n","        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.BatchNorm2d(out_channels),\n","                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.BatchNorm2d(out_channels))\n","\n","    def forward(self, x):\n","        x = self.block(x)\n","        return x\n","\n","\n","class DilatedConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dilation, padding):\n","        super(DilatedConvBlock, self).__init__()\n","        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding, dilation=dilation),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.BatchNorm2d(out_channels))\n","\n","    def forward(self, x):\n","        x = self.block(x)\n","        return x\n","\n","\n","\n","\n","class ConcatDoubleConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ConcatDoubleConvBlock, self).__init__()\n","        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.BatchNorm2d(out_channels),\n","                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","                                   nn.ReLU(inplace=True),\n","                                   nn.BatchNorm2d(out_channels))\n","\n","    def forward(self, x, skip):\n","        x = torch.cat((skip, x), dim=1)\n","        x = self.block(x)\n","        return x\n","\n","\n","\n","class MyDilatedConvUNet(nn.Module):\n","    def __init__(self, filters=44, depth=3, bottleneck_depth=6):\n","        super(MyDilatedConvUNet, self).__init__()\n","        self.depth = depth\n","        self.encoder_path = nn.ModuleList()\n","        src_in_channels = 3     # Geo-TIFF has four channels (R, G, B, and NIR)\n","        for d in range(depth):\n","            in_channels = src_in_channels if d == 0 else filters * 2 ** (d-1)\n","            self.encoder_path.append(\n","                DoubleConvBlock(in_channels, filters * 2 ** d))\n","        self.maxpool = nn.MaxPool2d(2, 2, padding=0)\n","        self.bottleneck_path = nn.ModuleList()\n","        for d in range(bottleneck_depth):\n","            in_channels = filters * 2 ** (depth - 1) if d == 0 else filters * 2 ** depth\n","            self.bottleneck_path.append(DilatedConvBlock(in_channels, filters * 2 ** depth, 2 ** d, 2 ** d))\n","        self.decoder_path = nn.ModuleList()\n","        for d in range(depth):\n","            in_channels = filters * 2 ** (depth - d)\n","            self.decoder_path.append(ConcatDoubleConvBlock(in_channels, filters * 2 ** (depth - d - 1)))\n","        self.up_path = nn.ModuleList()\n","        for d in range(depth):\n","            in_channels = filters * 2 ** (depth - d)\n","            self.up_path.append(nn.ConvTranspose2d(in_channels, filters * 2 ** (depth - d - 1),\n","                                                        kernel_size=4, stride=2, padding=1))\n","        out_channels = 4     # output channels (num_classes + 1(background))\n","        self.last_conv = nn.Conv2d(filters, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        skip = []\n","        for block in self.encoder_path:\n","            x = block(x)\n","            skip.append(x)\n","            x = self.maxpool(x)\n","        dilated = []\n","        for block in self.bottleneck_path:\n","            x = block(x)\n","            dilated.append(x)\n","        x = torch.stack(dilated, dim=-1).sum(dim=-1)  # sum over list\n","\n","        # up-sampling and double convolutions\n","        for d in range(self.depth):\n","            x = self.up_path[d](x)\n","            x = self.decoder_path[d](x, skip[-(d+1)])\n","\n","        return self.last_conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWNuzVTfzGUf"},"outputs":[],"source":["# HRNet\n","'''\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import logging\n","import functools\n","\n","import torch._utils\n","import torch.nn.functional as F\n","\n","BatchNorm2d = functools.partial(nn.BatchNorm2d)\n","# BatchNorm2d = nn.SynchBatchNorm(InPlaceABNSync, activation='none')\n","\n","BN_MOMENTUM = 0.01\n","logger = logging.getLogger(__name__)\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = out + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = BatchNorm2d(planes * self.expansion,\n","                               momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=False)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out = out + residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class HighResolutionModule(nn.Module):\n","    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n","                 num_channels, fuse_method, multi_scale_output=True):\n","        super(HighResolutionModule, self).__init__()\n","        self._check_branches(\n","            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n","\n","        self.num_inchannels = num_inchannels\n","        self.fuse_method = fuse_method\n","        self.num_branches = num_branches\n","\n","        self.multi_scale_output = multi_scale_output\n","\n","        self.branches = self._make_branches(\n","            num_branches, blocks, num_blocks, num_channels)\n","        self.fuse_layers = self._make_fuse_layers()\n","        self.relu = nn.ReLU(inplace=False)\n","\n","    def _check_branches(self, num_branches, blocks, num_blocks,\n","                        num_inchannels, num_channels):\n","        if num_branches != len(num_blocks):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n","                num_branches, len(num_blocks))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_channels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n","                num_branches, len(num_channels))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_inchannels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n","                num_branches, len(num_inchannels))\n","            logger.error(error_msg)\n","            raise ValueError(error_msg)\n","\n","    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n","                         stride=1):\n","        downsample = None\n","        if stride != 1 or \\\n","                self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.num_inchannels[branch_index],\n","                          num_channels[branch_index] * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(num_channels[branch_index] * block.expansion,\n","                            momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.num_inchannels[branch_index],\n","                            num_channels[branch_index], stride, downsample))\n","        self.num_inchannels[branch_index] = \\\n","            num_channels[branch_index] * block.expansion\n","        for i in range(1, num_blocks[branch_index]):\n","            layers.append(block(self.num_inchannels[branch_index],\n","                                num_channels[branch_index]))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n","        branches = []\n","\n","        for i in range(num_branches):\n","            branches.append(\n","                self._make_one_branch(i, block, num_blocks, num_channels))\n","\n","        return nn.ModuleList(branches)\n","\n","    def _make_fuse_layers(self):\n","        if self.num_branches == 1:\n","            return None\n","\n","        num_branches = self.num_branches\n","        num_inchannels = self.num_inchannels\n","        fuse_layers = []\n","        for i in range(num_branches if self.multi_scale_output else 1):\n","            fuse_layer = []\n","            for j in range(num_branches):\n","                if j > i:\n","                    fuse_layer.append(nn.Sequential(\n","                        nn.Conv2d(num_inchannels[j],\n","                                  num_inchannels[i],\n","                                  1,\n","                                  1,\n","                                  0,\n","                                  bias=False),\n","                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n","                elif j == i:\n","                    fuse_layer.append(None)\n","                else:\n","                    conv3x3s = []\n","                    for k in range(i - j):\n","                        if k == i - j - 1:\n","                            num_outchannels_conv3x3 = num_inchannels[i]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3,\n","                                            momentum=BN_MOMENTUM)))\n","                        else:\n","                            num_outchannels_conv3x3 = num_inchannels[j]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3,\n","                                            momentum=BN_MOMENTUM),\n","                                nn.ReLU(inplace=False)))\n","                    fuse_layer.append(nn.Sequential(*conv3x3s))\n","            fuse_layers.append(nn.ModuleList(fuse_layer))\n","\n","        return nn.ModuleList(fuse_layers)\n","\n","    def get_num_inchannels(self):\n","        return self.num_inchannels\n","\n","    def forward(self, x):\n","        if self.num_branches == 1:\n","            return [self.branches[0](x[0])]\n","\n","        for i in range(self.num_branches):\n","            x[i] = self.branches[i](x[i])\n","\n","        x_fuse = []\n","        for i in range(len(self.fuse_layers)):\n","            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n","            for j in range(1, self.num_branches):\n","                if i == j:\n","                    y = y + x[j]\n","                elif j > i:\n","                    width_output = x[i].shape[-1]\n","                    height_output = x[i].shape[-2]\n","                    y = y + F.interpolate(\n","                        self.fuse_layers[i][j](x[j]),\n","                        size=[height_output, width_output],\n","                        mode='bilinear', align_corners=False)\n","                else:\n","                    y = y + self.fuse_layers[i][j](x[j])\n","            x_fuse.append(self.relu(y))\n","\n","        return x_fuse\n","\n","\n","blocks_dict = {\n","    'BASIC': BasicBlock,\n","    'BOTTLENECK': Bottleneck\n","}\n","\n","\n","class HighResolutionNet(nn.Module):\n","\n","    def __init__(self, config, **kwargs):\n","        extra = config.MODEL.EXTRA\n","        super(HighResolutionNet, self).__init__()\n","\n","        # stem net\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=False)\n","\n","        self.stage1_cfg = extra['STAGE1']\n","        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n","        block = blocks_dict[self.stage1_cfg['BLOCK']]\n","        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n","        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n","        stage1_out_channel = block.expansion * num_channels\n","\n","        self.stage2_cfg = extra['STAGE2']\n","        num_channels = self.stage2_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage2_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition1 = self._make_transition_layer(\n","            [stage1_out_channel], num_channels)\n","        self.stage2, pre_stage_channels = self._make_stage(\n","            self.stage2_cfg, num_channels)\n","\n","        self.stage3_cfg = extra['STAGE3']\n","        num_channels = self.stage3_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage3_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition2 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage3, pre_stage_channels = self._make_stage(\n","            self.stage3_cfg, num_channels)\n","\n","        self.stage4_cfg = extra['STAGE4']\n","        num_channels = self.stage4_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage4_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition3 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage4, pre_stage_channels = self._make_stage(\n","            self.stage4_cfg, num_channels, multi_scale_output=True)\n","\n","        last_inp_channels = np.int(np.sum(pre_stage_channels))\n","\n","        self.last_layer = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=last_inp_channels,\n","                out_channels=last_inp_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0),\n","            BatchNorm2d(last_inp_channels, momentum=BN_MOMENTUM),\n","            nn.ReLU(inplace=False),\n","            nn.Conv2d(\n","                in_channels=last_inp_channels,\n","                out_channels=config.DATASET.NUM_CLASSES,\n","                kernel_size=extra.FINAL_CONV_KERNEL,\n","                stride=1,\n","                padding=1 if extra.FINAL_CONV_KERNEL == 3 else 0)\n","        )\n","\n","    def _make_transition_layer(\n","            self, num_channels_pre_layer, num_channels_cur_layer):\n","        num_branches_cur = len(num_channels_cur_layer)\n","        num_branches_pre = len(num_channels_pre_layer)\n","\n","        transition_layers = []\n","        for i in range(num_branches_cur):\n","            if i < num_branches_pre:\n","                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n","                    transition_layers.append(nn.Sequential(\n","                        nn.Conv2d(num_channels_pre_layer[i],\n","                                  num_channels_cur_layer[i],\n","                                  3,\n","                                  1,\n","                                  1,\n","                                  bias=False),\n","                        BatchNorm2d(\n","                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=False)))\n","                else:\n","                    transition_layers.append(None)\n","            else:\n","                conv3x3s = []\n","                for j in range(i + 1 - num_branches_pre):\n","                    inchannels = num_channels_pre_layer[-1]\n","                    outchannels = num_channels_cur_layer[i] \\\n","                        if j == i - num_branches_pre else inchannels\n","                    conv3x3s.append(nn.Sequential(\n","                        nn.Conv2d(\n","                            inchannels, outchannels, 3, 2, 1, bias=False),\n","                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=False)))\n","                transition_layers.append(nn.Sequential(*conv3x3s))\n","\n","        return nn.ModuleList(transition_layers)\n","\n","    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(inplanes, planes, stride, downsample))\n","        inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_stage(self, layer_config, num_inchannels,\n","                    multi_scale_output=True):\n","        num_modules = layer_config['NUM_MODULES']\n","        num_branches = layer_config['NUM_BRANCHES']\n","        num_blocks = layer_config['NUM_BLOCKS']\n","        num_channels = layer_config['NUM_CHANNELS']\n","        block = blocks_dict[layer_config['BLOCK']]\n","        fuse_method = layer_config['FUSE_METHOD']\n","\n","        modules = []\n","        for i in range(num_modules):\n","            # multi_scale_output is only used last module\n","            if not multi_scale_output and i == num_modules - 1:\n","                reset_multi_scale_output = False\n","            else:\n","                reset_multi_scale_output = True\n","            modules.append(\n","                HighResolutionModule(num_branches,\n","                                     block,\n","                                     num_blocks,\n","                                     num_inchannels,\n","                                     num_channels,\n","                                     fuse_method,\n","                                     reset_multi_scale_output)\n","            )\n","            num_inchannels = modules[-1].get_num_inchannels()\n","\n","        return nn.Sequential(*modules), num_inchannels\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.layer1(x)\n","\n","        x_list = []\n","        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n","            if self.transition1[i] is not None:\n","                x_list.append(self.transition1[i](x))\n","            else:\n","                x_list.append(x)\n","        y_list = self.stage2(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n","            if self.transition2[i] is not None:\n","                if i < self.stage2_cfg['NUM_BRANCHES']:\n","                    x_list.append(self.transition2[i](y_list[i]))\n","                else:\n","                    x_list.append(self.transition2[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        y_list = self.stage3(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n","            if self.transition3[i] is not None:\n","                if i < self.stage3_cfg['NUM_BRANCHES']:\n","                    x_list.append(self.transition3[i](y_list[i]))\n","                else:\n","                    x_list.append(self.transition3[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        x = self.stage4(x_list)\n","\n","        # Upsampling\n","        x0_h, x0_w = x[0].size(2), x[0].size(3)\n","        x1 = F.interpolate(x[1], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n","        x2 = F.interpolate(x[2], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n","        x3 = F.interpolate(x[3], size=(x0_h, x0_w), mode='bilinear', align_corners=False)\n","\n","        x = torch.cat([x[0], x1, x2, x3], 1)\n","\n","        x = self.last_layer(x)\n","\n","        return x\n","\n","    def init_weights(self, pretrained='', ):\n","        logger.info('=> init weights from normal distribution')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, std=0.001)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","        if os.path.isfile(pretrained):\n","            pretrained_dict = torch.load(pretrained)\n","            logger.info('=> loading pretrained model {}'.format(pretrained))\n","            model_dict = self.state_dict()\n","            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n","                               if k in model_dict.keys()}\n","            for k, _ in pretrained_dict.items():\n","                logger.info(\n","                    '=> loading {} pretrained model {}'.format(k, pretrained))\n","            model_dict.update(pretrained_dict)\n","            self.load_state_dict(model_dict)\n","\n","\n","def get_seg_model(cfg, **kwargs):\n","    model = HighResolutionNet(cfg, **kwargs)\n","    model.init_weights(cfg.MODEL.PRETRAINED)\n","\n","    return model\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e3d9a09"},"outputs":[],"source":["# method for hrnet init\n","'''\n","from yacs.config import CfgNode as CN\n","\n","_C = CN()\n","\n","_C.OUTPUT_DIR = ''\n","_C.LOG_DIR = ''\n","_C.GPUS = (0,)\n","_C.WORKERS = 4\n","_C.PRINT_FREQ = 20\n","_C.AUTO_RESUME = False\n","_C.PIN_MEMORY = True\n","_C.RANK = 0\n","\n","# Cudnn related params\n","_C.CUDNN = CN()\n","_C.CUDNN.BENCHMARK = True\n","_C.CUDNN.DETERMINISTIC = False\n","_C.CUDNN.ENABLED = True\n","\n","# common params for NETWORK\n","_C.MODEL = CN()\n","_C.MODEL.NAME = 'seg_hrnet'\n","_C.MODEL.PRETRAINED = ''\n","_C.MODEL.EXTRA = CN(new_allowed=True)\n","\n","_C.LOSS = CN()\n","_C.LOSS.USE_OHEM = False\n","_C.LOSS.OHEMTHRES = 0.9\n","_C.LOSS.OHEMKEEP = 100000\n","_C.LOSS.CLASS_BALANCE = True\n","\n","# DATASET related params\n","_C.DATASET = CN()\n","_C.DATASET.ROOT = ''\n","_C.DATASET.DATASET = 'cityscapes'\n","_C.DATASET.NUM_CLASSES = 19\n","_C.DATASET.TRAIN_SET = 'list/cityscapes/train.lst'\n","_C.DATASET.EXTRA_TRAIN_SET = ''\n","_C.DATASET.TEST_SET = 'list/cityscapes/val.lst'\n","\n","# training\n","_C.TRAIN = CN()\n","\n","_C.TRAIN.IMAGE_SIZE = [1024, 512]  # width * height\n","_C.TRAIN.BASE_SIZE = 2048\n","_C.TRAIN.DOWNSAMPLERATE = 1\n","_C.TRAIN.FLIP = True\n","_C.TRAIN.MULTI_SCALE = True\n","_C.TRAIN.SCALE_FACTOR = 16\n","\n","_C.TRAIN.LR_FACTOR = 0.1\n","_C.TRAIN.LR_STEP = [90, 110]\n","_C.TRAIN.LR = 0.01\n","_C.TRAIN.EXTRA_LR = 0.001\n","\n","_C.TRAIN.OPTIMIZER = 'sgd'\n","_C.TRAIN.MOMENTUM = 0.9\n","_C.TRAIN.WD = 0.0001\n","_C.TRAIN.NESTEROV = False\n","_C.TRAIN.IGNORE_LABEL = -1\n","\n","_C.TRAIN.BEGIN_EPOCH = 0\n","_C.TRAIN.END_EPOCH = 484\n","_C.TRAIN.EXTRA_EPOCH = 0\n","\n","_C.TRAIN.RESUME = False\n","\n","_C.TRAIN.BATCH_SIZE_PER_GPU = 32\n","_C.TRAIN.SHUFFLE = True\n","# only using some training samples\n","_C.TRAIN.NUM_SAMPLES = 0\n","\n","# testing\n","_C.TEST = CN()\n","\n","_C.TEST.IMAGE_SIZE = [2048, 1024]  # width * height\n","_C.TEST.BASE_SIZE = 2048\n","\n","_C.TEST.BATCH_SIZE_PER_GPU = 32\n","# only testing some samples\n","_C.TEST.NUM_SAMPLES = 0\n","\n","_C.TEST.MODEL_FILE = ''\n","_C.TEST.FLIP_TEST = False\n","_C.TEST.MULTI_SCALE = False\n","_C.TEST.SCALE_LIST = [1]\n","\n","# debug\n","_C.DEBUG = CN()\n","_C.DEBUG.DEBUG = False\n","_C.DEBUG.SAVE_BATCH_IMAGES_GT = False\n","_C.DEBUG.SAVE_BATCH_IMAGES_PRED = False\n","_C.DEBUG.SAVE_HEATMAPS_GT = False\n","_C.DEBUG.SAVE_HEATMAPS_PRED = False\n","\n","\n","def update_config(file):\n","    cfg = _C.clone()\n","    cfg.defrost()\n","    cfg.merge_from_file(file)\n","    cfg.freeze()\n","    return cfg\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78338b36","outputId":"0c6e4902-ac7e-4e22-b79f-a6af6efaebcf"},"outputs":[],"source":["# Model\n","if model_name == 'deeplabv3':\n","    model = models.segmentation.deeplabv3_resnet101(pretrained=False, progress=True, num_classes=4)\n","#elif model_name == 'hrnet_w18':\n","#    hrnet_cfg = update_config(os.path.join(workspace_path, 'models/hrnet_w18_config.yaml'))\n","#    model = get_seg_model(hrnet_cfg)\n","#elif model_name == 'hrnet_w48':\n","#    hrnet_cfg = update_config(os.path.join(workspace_path, 'models/hrnet_w48_config.yaml'))\n","#    model = get_seg_model(hrnet_cfg)\n","elif model_name == 'dilated_unet':\n","    model = MyDilatedConvUNet()\n","\n","model.to(device)\n","\n","print('number of parameters: ', count_parameters(model))"]},{"cell_type":"markdown","metadata":{"id":"467743f7"},"source":["### Opimizer 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"314acf1e"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"]},{"cell_type":"markdown","metadata":{"id":"QuJfaks1zbtC"},"source":["### 필요 함수 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c124f5df"},"outputs":[],"source":["def fitness_test(true, pred, num_classes=4):\n","    eps = 1e-7\n","    true_one_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n","    true_one_hot = true_one_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n","    pred_max = pred.argmax(1)      # (B, C, H, W) to (B, H, W)\n","    pix_acc = (true == pred_max.unsqueeze(1)).sum().float().div(true.nelement())\n","    pred_one_hot = F.one_hot(pred_max, num_classes=num_classes)   # (B, H, W) to (B, H, W, C)\n","    pred_one_hot = pred_one_hot.permute(0, 3, 1, 2)   # (B, H, W, C) to (B, C, H, W)\n","\n","    true_one_hot = true_one_hot.type(pred_one_hot.type())\n","    dims = (0,) + tuple(range(2, true.ndimension()))  # dims = (0, 2, 3)\n","    intersection = torch.sum(pred_one_hot & true_one_hot, dims)\n","    union = torch.sum(pred_one_hot | true_one_hot, dims)\n","    m_iou = (intersection / (union + eps)).mean()\n","\n","    return m_iou.item(), pix_acc.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v74FWycdzdev"},"outputs":[],"source":["# Loss 함수 정의\n","def ce_loss(true, logits, ignore=255):\n","    \"\"\"Computes the weighted multi-class cross-entropy loss.\n","    Args:\n","        true: a tensor of shape [B, 1, H, W].\n","        logits: a tensor of shape [B, C, H, W]. Corresponds to\n","            the raw output or logits of the model.\n","        ignore: the class index to ignore.\n","    Returns:\n","        ce_loss: the weighted multi-class cross-entropy loss.\n","    \"\"\"\n","    ce_loss = F.cross_entropy(\n","        logits.float(),\n","        true.squeeze(1).long(),    # [B, H, W]\n","        ignore_index=ignore,\n","    )\n","    return ce_loss\n","\n","\n","def dice_loss(true, logits, eps=1e-7):\n","    \"\"\"Computes the Sørensen–Dice loss.\n","    Note that PyTorch optimizers minimize a loss. In this\n","    case, we would like to maximize the dice loss so we\n","    return the negated dice loss.\n","    Args:\n","        true: a tensor of shape [B, 1, H, W].\n","        logits: a tensor of shape [B, C, H, W]. Corresponds to\n","            the raw output or logits of the model.\n","        eps: added to the denominator for numerical stability.\n","    Returns:\n","        dice_loss: the Sørensen–Dice loss.\n","    \"\"\"\n","    num_classes = logits.shape[1]\n","    if num_classes == 1:\n","        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n","        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n","        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n","        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n","        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n","        pos_prob = torch.sigmoid(logits)\n","        neg_prob = 1 - pos_prob\n","        probas = torch.cat([pos_prob, neg_prob], dim=1)\n","    else:\n","        # true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n","        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n","        true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n","        probas = F.softmax(logits, dim=1)\n","    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n","    dims = (0,) + tuple(range(2, true.ndimension()))        # dims = (0, 2, 3)\n","    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n","    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n","    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n","    return (1 - dice_loss)\n","\n","\n","def jaccard_loss(true, logits, eps=1e-7):\n","    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n","    Note that PyTorch optimizers minimize a loss. In this\n","    case, we would like to maximize the jaccard loss so we\n","    return the negated jaccard loss.\n","    Args:\n","        true: a tensor of shape [B, 1, H, W].\n","        logits: a tensor of shape [B, C, H, W]. Corresponds to\n","            the raw output or logits of the model.\n","        eps: added to the denominator for numerical stability.\n","    Returns:\n","        jacc_loss: the Jaccard loss.\n","    \"\"\"\n","    num_classes = logits.shape[1]\n","    if num_classes == 1:\n","        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n","        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n","        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n","        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n","        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n","        pos_prob = torch.sigmoid(logits)\n","        neg_prob = 1 - pos_prob\n","        probas = torch.cat([pos_prob, neg_prob], dim=1)\n","    else:\n","        true_1_hot = F.one_hot(true.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n","        true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n","        probas = F.softmax(logits, dim=1)\n","    true_1_hot = true_1_hot.type(logits.type()).contiguous()\n","    dims = (0,) + tuple(range(2, true.ndimension()))\n","    intersection = torch.sum(probas * true_1_hot, dims)\n","    cardinality = torch.sum(probas + true_1_hot, dims)\n","    union = cardinality - intersection\n","    jacc_loss = (intersection / (union + eps)).mean()\n","    return (1 - jacc_loss)"]},{"cell_type":"markdown","metadata":{"id":"9d1af165"},"source":["### 학습 함수 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bad17d99"},"outputs":[],"source":["def train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=400, use_scheduler=False, save_path='./ckpt'):\n","\n","    # Learning rate scheduler\n","    if use_scheduler:\n","        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n","    else:\n","        lr_scheduler = None\n","    start_epoch = 0\n","    resume = True\n","\n","    if not os.path.isdir(save_path):\n","        os.mkdir(save_path)\n","\n","    weight_file = save_path + '/{}.pt'.format(model_name)\n","\n","    best_fit = 0.0\n","    num_epochs = epochs\n","\n","    if resume:\n","        if os.path.exists(weight_file):\n","            checkpoint = torch.load(weight_file)\n","            model.load_state_dict(checkpoint['model'])\n","            start_epoch = checkpoint['epoch'] + 1\n","            best_fit = checkpoint['best_fit']\n","            print(\"Starting training for %g epochs...\" % start_epoch)\n","\n","    # Start training\n","\n","    for epoch in range(start_epoch, num_epochs):\n","        # loss, metric = train_one_epoch(model, optimizer, dataloader, device, epoch)\n","        t0 = time.time()\n","        loss = train_one_epoch(model, optimizer, train_dataloader, loss_func, device, epoch, num_epochs)\n","        t1 = time.time()\n","        print('[Epoch %g] loss=%.4f, time=%.1f' % (epoch, loss.item(), t1 - t0))\n","        if lr_scheduler is not None:\n","            lr_scheduler.step(loss)\n","        #tb_writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n","\n","        state = {'model_name': model_name, 'epoch': epoch, 'best_fit': best_fit, 'model': model.state_dict()}\n","        torch.save(state, weight_file)\n","\n","        #tb_writer.add_scalar('train_epoch_loss', loss, epoch)\n","\n","        # validation\n","        patch_size = patch_size\n","        fit = val_one_epoch(model, val_dataloader, device, epoch, num_epochs, patch_size)\n","        if fit > best_fit:\n","            print(\"best fit so far=>saved\")\n","            torch.save(state, os.path.join(save_path, '/{}_best.pt'.format(model_name)))\n","            best_fit = fit\n","\n","\n","def train_one_epoch(model, optimizer, data_loader, loss_func, device, epoch, num_epochs):\n","    model.train()\n","    losses = np.array([])\n","    metrics = np.array([])\n","    bi0 = epoch * len(data_loader)  # batch index\n","\n","    print(('\\n' + '%10s' * 2) % ('Epoch', 'loss'))\n","    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n","    s = ('%10s' + '%10.4f') % (\n","        '-/%g' % (num_epochs - 1), 0.0)\n","    pbar.set_description(s)\n","    for i, (imgs, targets) in pbar:\n","        imgs, targets = imgs.to(device), targets.to(device)\n","        if model_name == 'deeplabv3':\n","            preds = model(imgs)['out']\n","            targets = targets.long()\n","        elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n","            preds = model(imgs)\n","            h, w = preds.shape[2], preds.shape[3]\n","            targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n","        elif model_name == 'dilated_unet':\n","            preds = model(imgs)\n","            targets = targets.long()\n","            \n","        if loss_func == 'jaccard':\n","            loss = jaccard_loss(targets, preds)\n","        elif loss_func == 'dice':\n","            loss = dice_loss(targets, preds)\n","        elif loss_func == 'ce':\n","            loss = ce_loss(targets, preds)\n","        else:\n","            print('unsupported loss function')\n","            exit(1)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        with torch.no_grad():\n","            # cv2_imshow(imgs[0], preds[0])\n","            losses = np.append(losses, loss.item())\n","\n","            s = ('%10s' + '%10.4f') % (\n","                '%g/%g' % (epoch, num_epochs - 1), loss.item())\n","            pbar.set_description(s)\n","            bi = bi0 + i\n","            #tb_writer.add_scalar('train_batch_loss', loss.item(), bi)\n","\n","    epoch_loss = losses.mean()\n","\n","    return epoch_loss\n","\n","\n","def val_one_epoch(model, data_loader, device, epoch, num_epochs, patch_size):\n","    model.eval()\n","    m_iou_list = np.array([])\n","    pix_acc_list = np.array([])\n","\n","    print(('\\n' + '%10s' * 3) % ('Epoch(V)', 'mIOU', 'Accuracy'))\n","    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n","    s = ('%10s' + '%10.4f' + ' %8.4f') % (\n","        '-/%g' % (num_epochs - 1), 0.0, 0.0)\n","    pbar.set_description(s)\n","\n","    for i, (imgs, targets) in pbar:\n","        imgs, targets = imgs.to(device), targets.to(device)\n","        with torch.no_grad():\n","            if model_name == 'deeplabv3':\n","                preds = model(imgs)['out']\n","                targets = targets.long()\n","            elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n","                preds = model(imgs)\n","                h, w = preds.shape[2], preds.shape[3]\n","                targets = F.interpolate(targets.float(), size=(h, w), mode='nearest').long()\n","            elif model_name == 'dilated_unet':\n","                preds = model(imgs)\n","                targets = targets.long()\n","\n","            m_iou, pix_acc = fitness_test(targets, preds)\n","\n","            s = ('%10s' + '%10.4f' + ' %8.4f') % (\n","                '%g/%g' % (epoch, num_epochs - 1), m_iou, pix_acc)\n","            pbar.set_description(s)\n","            m_iou_list = np.append(m_iou_list, m_iou)\n","            pix_acc_list = np.append(pix_acc_list, pix_acc)\n","    val_m_iou_mean = m_iou_list.mean()\n","    val_pix_acc_mean = pix_acc_list.mean()\n","    print('[V] mIOU={:.3f}, Accuracy={:.3f}'.format(val_m_iou_mean, val_pix_acc_mean))\n","    #tb_writer.add_scalar('val_epoch_m_iou', val_m_iou_mean, epoch)\n","    #tb_writer.add_scalar('val_epoch_pix_acc', val_pix_acc_mean, epoch)\n","    return val_pix_acc_mean\n"]},{"cell_type":"markdown","metadata":{"id":"600d9790"},"source":["### 학습 시작"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b74e3dff","outputId":"b4ce8779-71be-4428-a357-78010400d46a"},"outputs":[],"source":["train(model, optimizer, train_dataloader, val_dataloader, loss_func, epochs, device, patch_size=patch_size, save_path=os.path.join(workspace_path, '/ckpt'))"]},{"cell_type":"markdown","metadata":{"id":"f8c906b3"},"source":["### 최고 성능 모델 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1f298c14"},"outputs":[],"source":["save_path=os.path.join(workspace_path, 'ckpt')\n","\n","checkpoint_path = os.path.join(save_path,'{}_best.pt'.format(model_name))\n","checkpoint = torch.load(checkpoint_path)\n","\n","model.load_state_dict(checkpoint['model'])\n","model.to(device)\n","\n","print('model load success')"]},{"cell_type":"markdown","metadata":{"id":"74453fb5"},"source":["### 테스트 데이터셋 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42e6ae95"},"outputs":[],"source":["test_rgb_path = os.path.join(workspace_path, 'data/test/rgb')\n","test_rgb_images = os.listdir(test_rgb_path)\n","test_rgb_images = [os.path.join(test_rgb_path, x) for x in test_rgb_images]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbeb921a"},"outputs":[],"source":["#empty value\n","test_label_path = os.path.join(workspace_path, 'data/test/label')\n","try:\n","    test_label_images = os.listdir(test_label_path)\n","except:\n","    test_label_images = []\n","test_label_images = [os.path.join(test_label_path, x) for x in test_label_images]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ba27f1e"},"outputs":[],"source":["test_dataset = CloudDataset(test_rgb_images, test_label_images,\n","                            transforms=val_transforms, is_train=False)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,\n","                                               num_workers=num_workers, pin_memory=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"5a055ede"},"source":["### 테스트 결과 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eadca7d5"},"outputs":[],"source":["model.eval()\n","\n","result_path = os.path.join(workspace_path, 'results')\n","os.makedirs(result_path, exist_ok=True)\n","\n","with torch.no_grad():\n","    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n","    for i, (imgs, img_path) in pbar:\n","        imgs = imgs.to(device)\n","        if model_name == 'deeplabv3':\n","            preds = model(imgs)['out']\n","        #elif model_name == 'hrnet_w18' or model_name == 'hrnet_w48':\n","        #    preds = model(imgs)\n","        #    h, w = preds.shape[2], preds.shape[3]\n","        elif model_name == 'dilated_unet':\n","            preds = model(imgs)\n","        \n","        pred_img = np.zeros((*list(preds.shape[2:]), 3), dtype=np.uint8)\n","        _, idx = preds.squeeze(0).max(0)\n","        pos = idx == 0\n","        pred_img[pos.cpu().numpy()] = [0, 0, 0]\n","        pos = idx == 1\n","        pred_img[pos.cpu().numpy()] = [0, 0, 255]\n","        pos = idx == 2\n","        pred_img[pos.cpu().numpy()] = [0, 255, 0]\n","        pos = idx == 3\n","        pred_img[pos.cpu().numpy()] = [0, 255, 255]\n","        \n","        cv2.imwrite(os.path.join(result_path, os.path.basename(img_path[0])), pred_img)\n"]},{"cell_type":"markdown","metadata":{"id":"18494383"},"source":["### Run-Length Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e8d274d"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4ebad00"},"outputs":[],"source":["def mask2rle(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formatted\n","    '''\n","    pixels= img.T.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd9e1cbb"},"outputs":[],"source":["test_label_file_list = os.listdir(result_path)\n","test_label_path_list = [os.path.join(result_path, x) for x in test_label_file_list]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92c7170e"},"outputs":[],"source":["rle_list = []\n","for file_path in test_label_path_list:\n","    img = cv2.imread(file_path)\n","    rle = mask2rle(img)\n","    rle_list.append(rle)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9851d2ed"},"outputs":[],"source":["my_dict = {'Image_Label':test_label_file_list, 'EncodedPixels':rle_list}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0873d66"},"outputs":[],"source":["my_df = pd.DataFrame(my_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7c595d0d"},"outputs":[],"source":["my_df.to_csv(os.path.join(workspace_path, 'submission.csv'), index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e74acfe"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.5 32-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"92b373647d70323cc2dc97beee21092f34aecbf86548c332dc7811da18a92f07"}}},"nbformat":4,"nbformat_minor":4}
